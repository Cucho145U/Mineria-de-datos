{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1adb5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7694d",
   "metadata": {},
   "source": [
    "## BagofWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03822d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 1),\n",
       " ('tangananika,', 1),\n",
       " ('me', 1),\n",
       " ('tangananika', 1),\n",
       " ('gusta', 1),\n",
       " ('nika', 3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bagOfWords(texto):\n",
    "    texto= re.sub(r'[^A-Za-z0-9 ]', '', texto).strip().lower()\n",
    "    texto=texto.split(\" \")\n",
    "\n",
    "    auxRDD=sc.parallelize(texto)\n",
    "    auxRDD= (auxRDD.\n",
    "             map(lambda x:[x,1]).\n",
    "             reduceByKey(lambda x,y:x+y).\n",
    "             map(lambda x:(x[0],x[1]) )\n",
    "            )\n",
    "    return auxRDD.collect()\n",
    "bagOfWords(\"me gusta el tangananika , tangananika nika nika nika\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668e2c3",
   "metadata": {},
   "source": [
    "## Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c27f139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el pato',\n",
       " 'pato juan',\n",
       " 'juan era',\n",
       " 'era bien',\n",
       " 'bien pata',\n",
       " 'pata de',\n",
       " 'de pato',\n",
       " 'pato tato']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ngramsTexto(n,texto):\n",
    "    texto=texto.split(\" \")\n",
    "    tamanio=len(texto)\n",
    "    arreglo=[]\n",
    "    for i in range (tamanio-1):\n",
    "        arreglo.append(str(texto[i]+\" \"+texto[i+1]))\n",
    "    return arreglo\n",
    "\n",
    "    \n",
    "def ngramsDatos(n,Datos):\n",
    "    auxRDD=sc.parallelize(Datos)\n",
    "    auxRDD=auxRDD.map(lambda x:ngramsTexto(n,x))\n",
    "    return auxRDD.collect()\n",
    "ngrams(2,\"el pato juan era bien pata de pato tato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146b231",
   "metadata": {},
   "source": [
    "## nSkipGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73232e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el era', 'pato bien', 'juan pata', 'era de', 'bien pato', 'pata tato']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nskipGramsTexto(n,k,texto):\n",
    "    texto=texto.split(\" \")\n",
    "    tamanio=len(texto)\n",
    "    arreglo=[]\n",
    "    for i in range (tamanio-k):\n",
    "        arreglo.append(str(texto[i]+\" \"+texto[i+k]))\n",
    "    return arreglo\n",
    "def nskipGramsDatos(n,Datos):\n",
    "    auxRDD=sc.parallelize(Datos)\n",
    "    auxRDD=auxRDD.map(lambda x:nskipGramsTexto(n,k,x))\n",
    "    return auxRDD.collect()\n",
    "nskipGrams(2,3,\"el pato juan era bien pata de pato tato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b26001",
   "metadata": {},
   "source": [
    "## TF.IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef2bacc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 1, 0.1549019599857432),\n",
       " ('feo', 1, 0.1549019599857432),\n",
       " ('paco', 2, 0.45593195564972433),\n",
       " ('juanito', 2, 0.45593195564972433),\n",
       " ('pato', 1, 0.1549019599857432)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def TFPorDocumento(documento):\n",
    "    documento=documento.split(\" \")\n",
    "    cantidadTotalDoc=len(documento)\n",
    "    auxRDD=sc.parallelize(documento)\n",
    "    auxRDD= (auxRDD.\n",
    "             map(lambda x:[x,1]).\n",
    "             reduceByKey(lambda x,y:x+y).\n",
    "             map(lambda x:(x[0],x[1],1+math.log10(x[1]/cantidadTotalDoc)) )\n",
    "            )\n",
    "    return auxRDD.collect()\n",
    "TFPorDocumento(\"juanito juanito paco paco pato el feo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d6c7249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'el': 0.17609125905568124,\n",
       " 'feo': 0.3010299956639812,\n",
       " 'paco': 0.3010299956639812,\n",
       " 'juanito': 0.17609125905568124,\n",
       " 'llamado': 0.17609125905568124,\n",
       " 'es': 0.17609125905568124,\n",
       " 'pato': 0.17609125905568124,\n",
       " 'ser': 0.17609125905568124}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IDFCorpus(corpus):\n",
    "    nroTotalDoc=len(corpus)\n",
    "    auxRDD=sc.parallelize(corpus)\n",
    "    auxRDD=(auxRDD.\n",
    "            flatMap(lambda x:list(set(x.split(\" \")))).\n",
    "             map(lambda x:[x,1]).\n",
    "             reduceByKey(lambda x,y:x+y).\n",
    "             map(lambda x:(x[0],x[1],math.log10(1+x[1]/nroTotalDoc)))\n",
    "\n",
    "            )\n",
    "    \n",
    "    aux=auxRDD.collect()\n",
    "    diccionario={}\n",
    "    for i in aux: diccionario[i[0]]=i[2]\n",
    "    return diccionario\n",
    "    #return corpusRDD.collect()\n",
    "IDFCorpus([\"juanito juanito paco paco pato el feo\",\"feo es ser llamado paco\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d7c6cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===documento  0 ====\n",
      "el 0.02727688116408227\n",
      "feo 0.04663013634285046\n",
      "paco 0.13724919463230698\n",
      "juanito 0.08028563211407898\n",
      "pato 0.02727688116408227\n",
      "===documento  1 ====\n",
      "feo 0.09061905828945656\n",
      "paco 0.09061905828945656\n",
      "llamado 0.05300875094999672\n",
      "es 0.05300875094999672\n",
      "ser 0.05300875094999672\n"
     ]
    }
   ],
   "source": [
    "def TFIDF(corpus):\n",
    "    idf=IDFCorpus(corpus)\n",
    "    for i in range (len(corpus)):\n",
    "        print(\"===documento \",i,\"====\")\n",
    "        TF=TFPorDocumento(corpus[i])\n",
    "        for palabra in TF:\n",
    "            print(palabra[0],palabra[2]*idf[palabra[0]])\n",
    "TFIDF([\"juanito juanito paco paco pato el feo\",\"feo es ser llamado paco\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
